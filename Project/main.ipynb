{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setting\n",
    "Google drive mount (for Colab users) and package importing.\n",
    "You can optionally install and import torchensemble package for ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Colab users\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/content/drive/{path to project directory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random  #\n",
    "import argparse  #\n",
    "import torchvision.transforms as transforms  #\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from data_utils import Mydataset, Mytensordataset, collate_fn\n",
    "from models import ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/snuml2021tmp/Ensemble-Pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only For Ensemble\n",
    "from torchensemble import GradientBoostingClassifier\n",
    "from torchensemble import SoftGradientBoostingClassifier\n",
    "from torchensemble import VotingClassifier\n",
    "from torchensemble import BaggingClassifier\n",
    "from torchensemble import FusionClassifier\n",
    "from torchensemble import SnapshotEnsembleClassifier\n",
    "from torchensemble.utils.logging import set_logger\n",
    "from torchensemble.utils import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Sample Visualization\n",
    "You can see actual sample images and sorted class indices. Additional matplotlib package is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for reference: see actual samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alphabet = {\n",
    "        'A(a)' : '0', \n",
    "        'B(b)' : '1', \n",
    "        'C(c)' : '2', \n",
    "        'D(d)' : '3', \n",
    "        'E(e)' : '4', \n",
    "        'F(f)' : '5', \n",
    "        'G(g)' : '6', \n",
    "        'H(h)' : '7', \n",
    "        'I(i)' : '8', \n",
    "        'J(j)' : '9', \n",
    "        'K(k)' : '10', \n",
    "        'L(l)' : '11', \n",
    "        'M(m)' : '12', \n",
    "        'N(n)' : '13', \n",
    "        'O(o)' : '14', \n",
    "        'P(p)' : '15', \n",
    "        'Q(q)' : '16', \n",
    "        'R(r)' : '17', \n",
    "        'S(s)' : '18', \n",
    "        'T(t)' : '19', \n",
    "        'U(u)' : '20', \n",
    "        'V(v)' : '21', \n",
    "        'W(w)' : '22', \n",
    "        'X(x)' : '23', \n",
    "        'Y(y)' : '24', \n",
    "        'Z(z)' : '25'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for reference: see actual samples\n",
    "idx = 10\n",
    "sample = np.load(f'./data/emnist/train/numpy/{idx}.npy')\n",
    "sample_target = np.loadtxt('./data/emnist/train/label.txt')[idx]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    ax = plt.gca()\n",
    "    ax.axes.xaxis.set_ticklabels([])\n",
    "    ax.axes.yaxis.set_ticklabels([])\n",
    "    plt.imshow(sample[i], cmap='gray')\n",
    "    \n",
    "plt.show()\n",
    "print(\"sorted label: \", end=' ')\n",
    "label_str = '('\n",
    "for i in range(10):\n",
    "    print(int(sample_target[i].item()), end=' ')\n",
    "    label_str += \" \" + list(alphabet.keys())[int(sample_target[i].item())]\n",
    "label_str += \" )\"\n",
    "print()\n",
    "print(label_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 0th GPU for training\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed to increase reproducibility\n",
    "# NOTE: Do not modify here!\n",
    "SEQUENCE_LENGTH = 10\n",
    "NUM_CLASSES = 26\n",
    "\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "%env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "\n",
    "def seed_worker(worker_seed):\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you can modify mean and std for normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_interval = 15\n",
    "max_epoch = 1\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: modify path for your setting\n",
    "\n",
    "# Option 1: use Mydataset (both for local and Colab users)\n",
    "train_ds = Mydataset('./data/emnist/train/numpy', './data/emnist/train/label.txt', transform=transform)\n",
    "valid_ds = Mydataset('./data/emnist/valid/numpy', './data/emnist/valid/label.txt', False, transform=transform)\n",
    "\n",
    "# Option 2: use Mytensordataset (Colab users should use this)\n",
    "# train_ds = Mytensordataset('./data/emnist/Colab/train/img.pt', './data/emnist/Colab/train/label.pt', True, transform=transform)\n",
    "# valid_ds = Mytensordataset('./data/emnist/Colab/valid/img.pt', './data/emnist/Colab/valid/label.pt', False, transform=transform)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, num_workers=num_workers, worker_init_fn=seed_worker, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, num_workers=num_workers, worker_init_fn=seed_worker, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add or modify your ConvLSTM's hyperparameter (keys and values)\n",
    "kwargs = {\n",
    "    'cnn_input_dim': 1,\n",
    "    'rnn_hidden_size': 8,\n",
    "    'rnn_num_layers': 1,\n",
    "    'rnn_dropout': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you can freely modify or add training hyperparameters\n",
    "print_interval = 15\n",
    "max_epoch = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-ensemble learning\n",
    "model = ConvLSTM(sequence_length=SEQUENCE_LENGTH, num_classes=NUM_CLASSES, **kargs).cuda()\n",
    "print(model)\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "model_optim = \n",
    "loss_func =\n",
    "# NOTE: you can define additional components\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_optim, loss_func, max_epoch, train_dl, valid_dl, load_path=None, save_path='./model.pt'):\n",
    "    ##############################################################################\n",
    "    #                          IMPLEMENT YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    # Load your states\n",
    "    loaded_epoch = 0\n",
    "    loaded_best_acc = -1\n",
    "    if load_path is not None:\n",
    "        state = torch.load(load_path)\n",
    "        model.load_state_dict(state[\"model\"])\n",
    "        model_optim.load_state_dict(state[\"optimizer\"])\n",
    "        loaded_epoch = state[\"epoch\"]\n",
    "        loaded_best_acc = state[\"best_acc\"]\n",
    "        # ...\n",
    "        \n",
    "    ##############################################################################\n",
    "    #                          END OF YOUR CODE                                  #\n",
    "    ##############################################################################\n",
    "    \n",
    "    best_valid_accuracy = 0 if loaded_best_acc == -1 else loaded_best_acc\n",
    "\n",
    "    for epoch in np.array(list(range(max_epoch - loaded_epoch))) + loaded_epoch:\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        model.train()\n",
    "        for step, sample in enumerate(train_dl):\n",
    "            img, label = sample  # (BxT, C=1, H, W), (BxT)\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            outputs = model((img, label))\n",
    "            ##############################################################################\n",
    "            #                          IMPLEMENT YOUR CODE                               #\n",
    "            ##############################################################################\n",
    "            # Problem5: implement optimization part (about four short lines are sufficient)\n",
    "\n",
    "            ##############################################################################\n",
    "            #                          END OF YOUR CODE                                  #\n",
    "            ##############################################################################\n",
    "            n_samples += img.size(0)\n",
    "            n_correct += (outputs.argmax(-1) == label).sum().item()\n",
    "            if (step + 1) % print_interval == 0:\n",
    "                print('epoch:', epoch + 1, 'step:', step + 1, 'loss:', loss.item(), 'accuracy:', 100 * (n_correct / n_samples))\n",
    "                \n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for step, sample in enumerate(valid_dl):\n",
    "                img, label = sample\n",
    "                img = img.cuda()\n",
    "                outputs = model(img)\n",
    "                pred = np.argmax(outputs.cpu().data.numpy(), axis=1)\n",
    "                label = label.data.numpy()\n",
    "                n_samples += label.shape[0]\n",
    "                n_correct += (pred == label).astype(float).sum()\n",
    "            valid_accuracy = 100 * (n_correct/n_samples)\n",
    "            if valid_accuracy > best_valid_accuracy:\n",
    "                print(\"New best valid accuracy, saving model\")\n",
    "                ##############################################################################\n",
    "                #                          IMPLEMENT YOUR CODE                               #\n",
    "                ##############################################################################\n",
    "                # Save your states\n",
    "                state = {\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"optimizer\": model_optim.state_dict(),\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"best_acc\": best_valid_accuracy,\n",
    "                    # ...\n",
    "                }\n",
    "                ##############################################################################\n",
    "                #                          END OF YOUR CODE                                  #\n",
    "                ##############################################################################\n",
    "                torch.save(state, save_path)\n",
    "                best_valid_accuracy = valid_accuracy\n",
    "            print('Valid epoch: %d, Valid accuracy: %.2f, Best valid accuracy: %.2f' % (epoch + 1, valid_accuracy, best_valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(valid_dl, load_path):\n",
    "    state = torch.load(load_path)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    n_samples = 0\n",
    "    n_correct = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for step, sample in enumerate(valid_dl):\n",
    "            img, label = sample\n",
    "            img = img.cuda()\n",
    "            outputs = model(img)\n",
    "            pred = np.argmax(outputs.cpu().data.numpy(), axis=1)\n",
    "            label = label.data.numpy()\n",
    "            n_samples += label.shape[0]\n",
    "            n_correct += (pred == label).astype(float).sum()\n",
    "        valid_accuracy = 100 * (n_correct/n_samples)\n",
    "        print('Valid accuracy: %.2f' % (valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = None\n",
    "train(model, model_optim, loss_func, max_epoch, train_dl, valid_dl, load_path=load_path, save_path='./model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and evaluate non-ensemble model\n",
    "load_path = './model.pt'\n",
    "eval(valid_dl, load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Optional: ENSEMBLE - model type / optimizer / scheduler ########\n",
    "estimator = ConvLSTM(sequence_length=SEQUENCE_LENGTH, num_classes=NUM_CLASSES, **kwargs).cuda()\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "# set ensemble model, optimizer, (optionally) lr scheduler\n",
    "model = \n",
    "model.set_optimizer(\n",
    "    \n",
    ")\n",
    "# Note: learning rate scheduler is optional\n",
    "model.set_scheduler(\n",
    "\n",
    ")\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = set_logger(\"Start Logging\", use_tb_logger=False)\n",
    "# epoch, optimizers, scheduler, best_acc, est_idx = io.load(model, './', use_scheduler=True)  # For load-and-rerun\n",
    "model.fit(\n",
    "    train_dl,\n",
    "    epochs=max_epoch,\n",
    "    log_interval=print_interval,\n",
    "    test_loader=valid_dl,\n",
    "    save_dir='./',\n",
    "    # retrain=True,  # For load-and-rerun\n",
    "    # loaded_optimizers=optimizers,  # For load-and-rerun\n",
    "    # loaded_scheduler=scheduler,  # For load-and-rerun\n",
    "    # loaded_epoch=epoch,  # For load-and-rerun\n",
    "    # loaded_est_idx=est_idx,  # For load-and-rerun\n",
    "    # loaded_best_acc=best_acc,  # For load-and-rerun\n",
    ")\n",
    "acc = model.evaluate(valid_dl)\n",
    "print(\"Valid accuracy: %.2f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and evaluate historical best model ensemble model\n",
    "estimator = ConvLSTM(sequence_length=SEQUENCE_LENGTH, num_classes=NUM_CLASSES, **kwargs).cuda()\n",
    "# Note: set ensemble type, optimizer, and scheduler exactly same with saved model\n",
    "model = \n",
    "model.set_optimizer(\n",
    "    \n",
    ")\n",
    "model.set_scheduler(\n",
    "\n",
    ")\n",
    "_, _, _, _ = io.load(model, './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(valid_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2021",
   "language": "python",
   "name": "ml2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
